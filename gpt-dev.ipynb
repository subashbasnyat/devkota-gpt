{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48d2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lspd.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02f0893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 119161\n"
     ]
    }
   ],
   "source": [
    "print(\"Length\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc205fb8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !,.:;?ँंःअआइईउऊऋएऐओऔकखगघङचछजझञटठडढणतथदधनपफबभमयरलवशषसहािीुूृेैोौ्ॐ।‍–‘’“”\n",
      "Vocab Size 74\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(\"Vocab Size\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80da3d9",
   "metadata": {},
   "source": [
    "### Character Level Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4676d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] #encoder: takes string, output list of integers\n",
    "decode = lambda l: \"\".join([itos[i] for i in l]) #decoder: takes the list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0589ae43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 48, 58, 48, 1, 53, 55, 38, 57, 1, 46, 1, 42, 55, 24, 49]\n",
      "जरुर साथी म पागल\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"जरुर साथी म पागल\"))\n",
    "print(decode(encode(\"जरुर साथी म पागल\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded158a9",
   "metadata": {},
   "source": [
    "Sentence Piece -> Subword\n",
    "OpenAI -> tiktoken (GPT uses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "987d99ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /home/mrmojorisin/anaconda3/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/mrmojorisin/anaconda3/lib/python3.9/site-packages (from tiktoken) (2.28.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/mrmojorisin/anaconda3/lib/python3.9/site-packages (from tiktoken) (2022.3.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mrmojorisin/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mrmojorisin/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mrmojorisin/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mrmojorisin/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9dbe6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ef86ca2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "enc.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e354e4e9-90f8-4025-af67-4d9e66297e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19585]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"Joe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9c03f736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11976, 103, 48077, 11976, 245, 11976, 110]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"पागल\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5b93c940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'पागल'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode([11976, 103, 48077, 11976, 245, 11976, 110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9289ed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([119161]) torch.int64\n",
      "tensor([41, 28, 55, 34, 57,  1, 29, 55, 41, 63, 53, 65,  1, 54, 61,  1, 46, 61,\n",
      "        48, 55,  1, 42, 65, 48, 55, 36,  1,  2,  1, 11, 22, 61, 49, 57,  1, 46,\n",
      "        49, 55, 14,  3,  0, 46, 41, 22, 63,  1, 50, 41, 46, 55,  1, 41, 41, 56,\n",
      "        45, 65, 41, 61,  1, 24, 48, 57,  1, 50, 56, 48, 54,  1, 29, 49, 55, 14,\n",
      "         1,  2,  0, 41, 41, 56, 45, 65, 41, 61,  1, 24, 48, 57,  1, 50, 56, 48,\n",
      "        54,  1, 29, 49, 55, 14,  3,  0, 49, 63])\n"
     ]
    }
   ],
   "source": [
    "# Encode entire text dataset and store it in torch.Tensor\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ac675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107244"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and validation sets\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e740d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41, 28, 55, 34, 57,  1, 29, 55, 41])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll not feed entire text into the transformers at once. Computationally expensive.\n",
    "# Work with chunks of data\n",
    "# with Max Length, block_size\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f064e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([41]), target is: 28\n",
      "When input is tensor([41, 28]), target is: 55\n",
      "When input is tensor([41, 28, 55]), target is: 34\n",
      "When input is tensor([41, 28, 55, 34]), target is: 57\n",
      "When input is tensor([41, 28, 55, 34, 57]), target is: 1\n",
      "When input is tensor([41, 28, 55, 34, 57,  1]), target is: 29\n",
      "When input is tensor([41, 28, 55, 34, 57,  1, 29]), target is: 55\n",
      "When input is tensor([41, 28, 55, 34, 57,  1, 29, 55]), target is: 41\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When input is {context}, target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1bbac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1,  2,  1, 41, 28, 58, 41, 59],\n",
      "        [65, 24, 53, 65, 50, 55, 48, 65],\n",
      "        [53, 65, 37, 62,  1, 28,  1, 46],\n",
      "        [ 2,  0, 18, 22,  1, 37, 48, 26]])\n",
      "Targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 2,  1, 41, 28, 58, 41, 59,  1],\n",
      "        [24, 53, 65, 50, 55, 48, 65, 38],\n",
      "        [65, 37, 62,  1, 28,  1, 46, 61],\n",
      "        [ 0, 18, 22,  1, 37, 48, 26, 65]])\n",
      "------\n",
      "When input is [1], target is: 2\n",
      "When input is [1, 2], target is: 1\n",
      "When input is [1, 2, 1], target is: 41\n",
      "When input is [1, 2, 1, 41], target is: 28\n",
      "When input is [1, 2, 1, 41, 28], target is: 58\n",
      "When input is [1, 2, 1, 41, 28, 58], target is: 41\n",
      "When input is [1, 2, 1, 41, 28, 58, 41], target is: 59\n",
      "When input is [1, 2, 1, 41, 28, 58, 41, 59], target is: 1\n",
      "When input is [65], target is: 24\n",
      "When input is [65, 24], target is: 53\n",
      "When input is [65, 24, 53], target is: 65\n",
      "When input is [65, 24, 53, 65], target is: 50\n",
      "When input is [65, 24, 53, 65, 50], target is: 55\n",
      "When input is [65, 24, 53, 65, 50, 55], target is: 48\n",
      "When input is [65, 24, 53, 65, 50, 55, 48], target is: 65\n",
      "When input is [65, 24, 53, 65, 50, 55, 48, 65], target is: 38\n",
      "When input is [53], target is: 65\n",
      "When input is [53, 65], target is: 37\n",
      "When input is [53, 65, 37], target is: 62\n",
      "When input is [53, 65, 37, 62], target is: 1\n",
      "When input is [53, 65, 37, 62, 1], target is: 28\n",
      "When input is [53, 65, 37, 62, 1, 28], target is: 1\n",
      "When input is [53, 65, 37, 62, 1, 28, 1], target is: 46\n",
      "When input is [53, 65, 37, 62, 1, 28, 1, 46], target is: 61\n",
      "When input is [2], target is: 0\n",
      "When input is [2, 0], target is: 18\n",
      "When input is [2, 0, 18], target is: 22\n",
      "When input is [2, 0, 18, 22], target is: 1\n",
      "When input is [2, 0, 18, 22, 1], target is: 37\n",
      "When input is [2, 0, 18, 22, 1, 37], target is: 48\n",
      "When input is [2, 0, 18, 22, 1, 37, 48], target is: 26\n",
      "When input is [2, 0, 18, 22, 1, 37, 48, 26], target is: 65\n"
     ]
    }
   ],
   "source": [
    "# Batch Dimension\n",
    "# Parallel Processing, Multiple chunks all at the same time.\n",
    "torch.manual_seed(420)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "#     print(f\"len(data): {len(data)}, block_size: {block_size}, batch_size: {batch_size}, len(data) - block_size: {len(data) - block_size}\")\n",
    "#     print(f\"IX: {ix}\")\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "print(\"Inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"Targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print(\"------\")\n",
    "\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"When input is {context.tolist()}, target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa03fdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5547, 44831, 79558, 81261])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(107236,(4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b09333ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll feed xb into the transformers, transformers will process the input and look upto yb for correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "913dd9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.token_embedding_table Embedding(74, 74)\n",
      "torch.Size([32, 74])\n",
      "tensor(4.8599, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "लञअ’ढआखगप डऔ\n",
      "ःशवऊै‘औई‘ल‍ठगःबपेः‍शई:ँिथह‘ःूूृयइय?.अओलढठबूक“ऊककखत?झधिमकथधच सटीरओपॐढँदऐ,‘?शोदअसण;ढ्घएअष\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(420)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    '''\n",
    "        It is simply a lookup table of logits for the next character given a previous character\n",
    "    '''\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # Each token directly reads off the logits for the next token from the lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        print(\"self.token_embedding_table\", self.token_embedding_table)\n",
    "        # print(\"Embedding Weights\", self.token_embedding_table.weight[49])\n",
    "        # print(\"Embedding Weights\", self.token_embedding_table.weight[31])\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensors of integers\n",
    "        logits = self.token_embedding_table(idx) # B, T, C\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Cross Entropy wants B, T, C. So,\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the prediction\n",
    "            logits, loss = self(idx)\n",
    "            # print(\"Logits\", logits)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # Becomes (B,C)\n",
    "            # print(\"Logits\", logits)\n",
    "            # apply softmax to get the probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # print(\"Probs\", probs)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # print(\"ID Next\", idx_next)\n",
    "            idx = torch.cat((idx, idx_next), dim = 1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d187e673-0684-4e35-85c5-97c9f829f8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.7515, -0.9941, -0.6508,  ..., -0.5430, -0.0459,  0.2193],\n",
       "        [ 0.4391, -0.9723,  1.0642,  ...,  0.4268, -0.2010,  0.7361],\n",
       "        [-1.5503, -0.4205,  1.4080,  ...,  1.3648, -0.8378, -0.0643],\n",
       "        ...,\n",
       "        [ 0.8211, -1.3542,  0.7526,  ..., -0.7964,  0.8806,  0.4518],\n",
       "        [ 0.7508,  0.3263, -1.6027,  ..., -0.1268,  0.4731, -0.9279],\n",
       "        [-0.9792, -1.2182, -0.3756,  ...,  0.8577,  1.2365,  0.6499]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "x = nn.Embedding(vocab_size, vocab_size)\n",
    "x.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b570c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0472, -0.4430, -0.2003,  2.4293],\n",
      "        [-0.7042, -1.3085,  1.0577, -0.7016],\n",
      "        [ 1.0019, -0.4185, -0.8609, -1.4439],\n",
      "        [-0.3811,  0.8902,  1.1004, -0.8110]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0019, -0.4185, -0.8609, -1.4439]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = nn.Embedding(4,4)\n",
    "print(emb.weight)\n",
    "input = torch.LongTensor([[2]])\n",
    "emb(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48a05204",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f7b982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5646562576293945\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcfb9b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ने वाई तो,\n",
      "प्क\n",
      " ला अम दिन्झन घरदछलारम इर्न गुको, ले भुकदछि भक !\n",
      "फै  दुननान हायुनवशीबायो यङ्न्र गर्वी उस्ताहो झै मुला,\n",
      "हिन्याँ उत्बा नी बसुभो ।\n",
      "व्तिएको,\n",
      "बनत् गहातिएकेरैं, लेँदनिन जहरी औँदाट?\n",
      "चूत्विमर्छ,\n",
      "कल गुनमदैओरुज्नकारी टुध रको,\n",
      "मासङ्चिर !\n",
      "जगडाल्दिनुसल्त्छनी बा चान्दिमुकलौं योसाहाबहा\n",
      "आँ.ऊ प्काइ शब\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx, max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d80b9f",
   "metadata": {},
   "source": [
    "We're only looking at the last character to predict the next.\n",
    "Now, these tokens have to start talking to each other and figuring out what is in the context.\n",
    "This is how we're going to kick-off Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dcf40d",
   "metadata": {},
   "source": [
    "The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6d6151bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f381e",
   "metadata": {},
   "source": [
    "We have 8 tokens in a batch. They're currently not talking to each other.\n",
    "Token at 5th location should not communicate with the token at 6th, 7th, 8th location.\n",
    "Token at 5th location should only communicate with the token at 1st, 2nd, 3rd, 4th location.\n",
    "Information flows from previous to next context.\n",
    "What is the easiest way for tokens to communicate?\n",
    "Average of all preceding elements. Weak & Lossy. That's ok for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8ed4d609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0070,  0.5044],\n",
       "        [ 0.6704, -0.3829],\n",
       "        [ 0.0302,  0.3826],\n",
       "        [-0.5131,  0.7104],\n",
       "        [ 1.8092,  0.4352],\n",
       "        [ 2.6453,  0.2654],\n",
       "        [ 0.9235, -0.4376],\n",
       "        [ 2.0182,  1.3498]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xbag_of_words = averaging\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        # For this batch, everything upto the tth token\n",
    "        xprev = x[b, :t+1] #(t,C)\n",
    "        # Averaging out the time\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1714b1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0070,  0.5044],\n",
       "        [ 0.3317,  0.0608],\n",
       "        [ 0.2312,  0.1681],\n",
       "        [ 0.0451,  0.3037],\n",
       "        [ 0.3979,  0.3300],\n",
       "        [ 0.7725,  0.3192],\n",
       "        [ 0.7941,  0.2111],\n",
       "        [ 0.9471,  0.3534]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41286e8",
   "metadata": {},
   "source": [
    "This is very inefficient. The trick is to use Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b83af53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "b =\n",
      "tensor([[1., 6.],\n",
      "        [2., 7.],\n",
      "        [5., 5.]])\n",
      "c =\n",
      "tensor([[ 8., 18.],\n",
      "        [ 8., 18.],\n",
      "        [ 8., 18.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "a = torch.ones(3,3)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a =')\n",
    "print(a)\n",
    "print('b =')\n",
    "print(b)\n",
    "print('c =')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ce085d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8aecd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "b =\n",
      "tensor([[1., 6.],\n",
      "        [2., 7.],\n",
      "        [5., 5.]])\n",
      "c =\n",
      "tensor([[ 1.,  6.],\n",
      "        [ 3., 13.],\n",
      "        [ 8., 18.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a =')\n",
    "print(a)\n",
    "print('b =')\n",
    "print(b)\n",
    "print('c =')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7e8a2b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b =\n",
      "tensor([[1., 6.],\n",
      "        [2., 7.],\n",
      "        [5., 5.]])\n",
      "c =\n",
      "tensor([[1.0000, 6.0000],\n",
      "        [1.5000, 6.5000],\n",
      "        [2.6667, 6.0000]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a/torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a =')\n",
    "print(a)\n",
    "print('b =')\n",
    "print(b)\n",
    "print('c =')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0c18e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 2\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei/wei.sum(1, keepdim=True)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dd8174cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2 = wei @ x # (B, T,T) @ (B, T, C) --> (B, T, C)\n",
    "xbow2\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6481b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wei:  tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Wei2:  tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Wei3:  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "print(\"Wei: \", wei)\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "print(\"Wei2: \", wei)\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(\"Wei3: \", wei)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2975a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wei:  tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Wei2:  tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Wei3:  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention basics\n",
    "torch.manual_seed(420)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "# These tokens will start looking at each other for affinities\n",
    "wei = torch.zeros((T,T))\n",
    "print(\"Wei: \", wei)\n",
    "\n",
    "# Future can't communicate with the past\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "print(\"Wei2: \", wei)\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(\"Wei3: \", wei)\n",
    "out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4c757",
   "metadata": {},
   "source": [
    "We don't want\n",
    "`wei = torch.zeros((T,T))`\n",
    "to be all uniform. \n",
    "Different tokens will find more other tokens more or less interesting.\n",
    "If I'm a vowel, maybe I'm looking for consonant in the past.\n",
    "Maybe I want to know what those consonants are. I want that information to flow to me.\n",
    "I want to gather information in the past. But, I want to do that in data-dependent way.\n",
    "\n",
    "This is the problem, self-attention solves\n",
    "\n",
    "Every single node or token at each position, emit two vectors (query, key)\n",
    "\n",
    "query -> What am I looking for\n",
    "\n",
    "key -> what do I contain\n",
    "\n",
    "Dot product between keys and queries\n",
    "\n",
    "My query dot products with all the keys of all the tokens. And the dot product becomes `wei`.\n",
    "\n",
    "If key and query align, they'll yield high amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5f1bb822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei tensor([[ 2.2728,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.5068, -0.5077,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.4327, -0.2557, -0.4741,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 1.3287, -2.1195, -2.6443, -0.4957,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.4125, -1.2480, -3.1376, -0.5089, -2.1272,    -inf,    -inf,    -inf],\n",
      "        [ 0.0485,  1.0301,  1.1512,  1.4882, -0.9631,  0.1086,    -inf,    -inf],\n",
      "        [ 1.1692,  1.6438,  1.0493,  0.5698,  0.8746,  1.9510,  0.6115,    -inf],\n",
      "        [-1.4170,  0.7859, -2.6072,  1.0348,  0.4087,  0.3289, -1.6117,  2.7514]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self-attention\n",
    "torch.manual_seed(420)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "# let's see a single head of self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "print(\"wei\", wei[0])\n",
    "wei = F.softmax(wei, dim=1)\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cab5b187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0731, 0.0504, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0679, 0.0648, 0.0912, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1663, 0.0100, 0.0104, 0.0596, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0665, 0.0240, 0.0064, 0.0588, 0.0271, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0462, 0.2343, 0.4631, 0.4333, 0.0867, 0.1168, 0.0000, 0.0000],\n",
       "        [0.1418, 0.4329, 0.4182, 0.1729, 0.5445, 0.7375, 0.9023, 0.0000],\n",
       "        [0.0107, 0.1836, 0.0108, 0.2753, 0.3417, 0.1456, 0.0977, 1.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aa8f94fc-b731-4fc4-811d-534947933ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0456e-01, -1.5550e-01,  2.0127e-01,  1.8277e-01, -5.1866e-03,\n",
       "         -1.5409e-01,  9.9967e-02, -5.7802e-02, -8.7813e-02, -1.8669e-01,\n",
       "         -2.4114e-02,  7.1841e-02, -2.6539e-01,  1.8791e-01,  1.1083e-01,\n",
       "          4.5298e-01],\n",
       "        [ 1.5799e-01, -1.0105e-03,  5.8079e-02,  4.8808e-02,  8.2898e-03,\n",
       "          2.0822e-02,  4.1613e-02,  3.6835e-04, -1.0373e-02, -9.4940e-02,\n",
       "          4.6224e-02, -1.4178e-02, -8.9967e-02,  6.3453e-02, -3.3155e-02,\n",
       "          1.0161e-01],\n",
       "        [ 2.4133e-01, -4.4916e-02, -8.9540e-03,  2.2071e-02, -6.1946e-03,\n",
       "          1.6568e-01,  7.7308e-02, -4.1726e-02, -9.1936e-03, -1.4985e-01,\n",
       "          1.1256e-01, -2.5931e-02, -9.1055e-02,  4.3798e-02, -1.1253e-01,\n",
       "          3.1679e-02],\n",
       "        [ 2.7880e-01, -2.2266e-02,  9.8550e-02,  1.0765e-01, -2.0372e-02,\n",
       "          3.1448e-03,  7.8094e-02, -5.8466e-02, -2.9769e-02, -8.1342e-02,\n",
       "         -1.4482e-02, -1.2349e-02, -1.0809e-01,  7.1086e-02,  3.2396e-02,\n",
       "          1.8712e-01],\n",
       "        [ 1.3364e-01,  4.0470e-02,  3.5189e-02,  7.9507e-02, -5.9504e-02,\n",
       "          3.4779e-02,  7.2957e-02, -5.8178e-02,  1.6933e-03, -5.6087e-02,\n",
       "         -6.1836e-03, -5.0698e-02, -5.1063e-02,  3.5096e-02, -9.8853e-03,\n",
       "          8.7125e-02],\n",
       "        [ 8.7209e-01,  2.2493e-01, -1.0387e-02,  2.2186e-01, -3.7513e-01,\n",
       "          1.1198e+00,  5.2642e-01, -5.0680e-01,  2.5831e-02, -4.5369e-01,\n",
       "          2.6649e-01, -4.1771e-01, -2.3733e-01,  3.4672e-02, -4.7998e-01,\n",
       "         -6.4279e-02],\n",
       "        [ 1.6038e+00,  7.2552e-01, -7.3058e-02,  7.3049e-02, -1.1461e+00,\n",
       "          1.0618e+00,  7.6772e-01, -6.4880e-01, -1.6804e-01, -1.0386e+00,\n",
       "         -1.4205e-01, -3.7107e-01, -7.6624e-01,  1.0606e+00, -4.5531e-01,\n",
       "          4.8295e-01],\n",
       "        [ 6.6665e-01,  3.6335e-01,  2.4658e-01,  1.3311e+00, -9.1840e-01,\n",
       "         -1.6962e-01, -5.4303e-01, -9.3691e-01, -9.1978e-02,  4.0910e-01,\n",
       "         -3.9194e-01, -5.3645e-01,  2.5986e-02, -4.6111e-01,  3.4348e-02,\n",
       "         -1.5156e-01]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aaa9e1",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b2d94a9e-6d1e-42dc-b36a-e78ee620bc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9264)\n",
      "tensor(1.0146)\n",
      "tensor(15.0543)\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2,-1)\n",
    "\n",
    "print(k.var())\n",
    "print(q.var())\n",
    "print(wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4c0d39da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0254)\n",
      "tensor(0.9833)\n",
      "tensor(1.0192)\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2,-1) * head_size**-0.5\n",
    "\n",
    "print(k.var())\n",
    "print(q.var())\n",
    "print(wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "364a92c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5]), dim=-1)\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b63d210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5939e-03, 1.3117e-05, 3.9102e-02, 1.3117e-05, 9.5928e-01])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5])*16, dim=-1) # gets too peaky, converges to one-hot\n",
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f0fee035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(sm, label=\"Small\")\n",
    "plt.plot(lg, label=\"Large\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff0fb4-1459-4b29-8e21-e52fbf166ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
